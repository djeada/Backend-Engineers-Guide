## Serializable Isolation
Serializable isolation is the best and most reliable way of dealing with concurrency issues, however it can come with a performance penalty. There are a few main ways of dealing with serializable isolation in databases:

### Actual Serial Execution
Actual serial execution is literally implementing transactions serially on a single thread. With RAM now being cheap enough to keep all data in memory, this can be a viable option. However, it is important to note that the throughput is limited to a single CPU core and that it is not possible to allow multiple statements per transaction (such as an HTTP request) due to network overhead which would create massive delays. Instead, the entire transaction should be sent to the database ahead of time as a stored procedure. As it can be difficult to write these and version control them, less popular languages can be used. If the data can be partitioned so that each transaction only reads and writes from a single partition, throughput can be increased significantly.

### Two Phase Locking
Two phase locking is when multiple transactions can concurrently read the same object as long as nobody is writing to it, but writes require exclusive access to the lock. This can result in frequent deadlocks, in which case the database must abort one of the transactions and let the other complete before retrying it. This can take a great performance hit due to the overhead of locking and any two transactions which even remotely overlap have to wait on one another. In order to avoid this, predicate locks can be used, which work similarly to exclusive shared locks, but can apply to all objects matching a given search condition. Index-range locking can also be used, which is an approximation of predicate locking, and simplifies a predicate by making it match a greater set of objects.

### Serializable Snapshot Isolation
Serializable snapshot isolation is full serializability with a small concurrency penalty. It uses optimistic concurrency control, meaning there are no changes until something bad happens at which point transactions must be aborted and retried. This can be bad if things need to be retried too often. All reads occur from snapshots and the database needs to tell when a premise that a transaction has acted on has since changed. To detect reads of a stale object, a check is made at read time to see if any uncommitted writes have been ignored and before making the corresponding write from the first read, a check is made to see if any of the ignored writes have since committed, and if so the transaction is aborted. To detect writes that affect prior reads, the transactions which have read a given object are tracked, so that if the object changes, the other transaction will be aborted when it tries to write.
